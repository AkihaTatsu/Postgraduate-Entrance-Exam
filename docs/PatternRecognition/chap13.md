# 模式识别系统的评价

## 监督模式识别的错误率估计
### 训练错误率
**分类器设计完成后，用分类器来对全部训练样本进行分类，其中错误分类的样本所占的比例。**
这种错误率是偏乐观的，因分类器设计过程中已经用到了所有样本的信息，因此这种训练错误率不能忠实地反映分类器在未来样本上的表现，即不能反映分类器的推广能力。
事实上，**训练错误率就是经验风险**；而经验风险能够一定程度上反映推广能力。

### 测试错误率
**在实际问题的样本中划分出一部分作为独立的测试集（也称作检验集或考试集），或在已知样本外有条件地采集更多样本，用这一部分样本估计分类器性能。**

这一错误率的性质在二分类问题的以下两种情况中进行简单讨论。

#### 先验概率$P(\omega_1)$、$P(\omega_2)$未知——随机抽样
假设分类器对$N$个样本进行测试，结果错分了$k$个，则$k$为一个离散随机变量，用$\varepsilon$表示真实错误率，给定$\varepsilon$后$k$的密度函数为二项分布
$$P(k) = C_N^k \varepsilon^k (1 - \varepsilon)^k$$

其中$C_N^k = \dfrac{N!}{k!(N - k)!}$；从而$\varepsilon$的最大似然估计$\hat{\varepsilon}$满足
$$\dfrac{\partial P(k)}{\partial \varepsilon} = \dfrac{k}{\varepsilon} - \dfrac{N - k}{1 - \varepsilon} = 0$$

解得$$\varepsilon = \dfrac{k}{N}$$即最大似然估计$\hat{\varepsilon}$为被错分样本数$k$和总考试样本数$N$之比。

对于$\hat{\varepsilon}$这一估计量，其期望和方差分别为
$$\begin{gathered}
    E[\hat{\varepsilon}] = E \left[ \dfrac{k}{N} \right] = \dfrac{E[k]}{N} = \dfrac{N\varepsilon}{N} = \varepsilon \\
    \text{var}(\hat{\varepsilon}) = \dfrac{\text{var}(k)}{N^2} = \dfrac{\varepsilon(1 - \varepsilon)}{N} \\
\end{gathered}$$

由期望$E[\hat{\varepsilon}] = \varepsilon$可知，$\hat{\varepsilon}$为$\varepsilon$的无偏估计量。
在$95\%$的置信系数下，置信区间$(\varepsilon_1, \varepsilon_2)$与$\hat{\varepsilon}$和$N$的关系为$$P(\varepsilon_1 \leq \varepsilon \leq \varepsilon_2) = 1 - \dfrac{\beta}{100} = 0.95$$其中$\beta$为置信系数。

显然，测试样本数$N$越多，则估计出的错误率$\varepsilon$的置信区间越小。

#### 先验概率$P(\omega_1)$、$P(\omega_2)$已知——选择性抽样
当知道两类先验概率$P(\omega_1)$、$P(\omega_2)$时，可分别从类别$\omega_1$、$\omega_2$总体中抽取$N_1 = P(\omega_1)N$和$N_2 = P(\omega_2)N$个样本，并将这$N_1 + N_2 = N$个样本作为检验集。

设$k_1$、$k_2$分别为考试集中属于$\omega_1$及$\omega_2$类别但被错分的样本数，因$k_1$、$k_2$是相互独立的，故$k_1$、$k_2$的联合概率为
$$P(k_1, k_2) = P(k_1)P(k_2) = \prod_{i = 2}^2 C_{N_i}^{k_i} \varepsilon_i^{k_i} (1 - \varepsilon_i)^{N_i - k_i}$$

其中$\varepsilon_i$为$\omega_i$类别的真实错误率。
类似地，可以得到$\varepsilon_i$的最大似然估计为$$\hat{\varepsilon}_i = \dfrac{k_i}{N_i},\quad i = 1, 2$$

而总的错误率估计为
$$\hat{\varepsilon}' = P(\omega_1)\hat{\varepsilon}_1 + P(\omega_2)\hat{\varepsilon}_2 = \sum_{i = 1}^2 P(\omega_i) \hat{\varepsilon}_i$$

从而$\hat{\varepsilon}'$的期望和方差为
$$\begin{gathered}
    E[\hat{\varepsilon}'] = P(\omega_1) E[\hat{\varepsilon}_1] + P(\omega_2) E[\hat{\varepsilon}_2] = P(\omega_1)\varepsilon_1 + P(\omega_2)\varepsilon_2 = \varepsilon \\
    \text{var}(\hat{\varepsilon}') = \dfrac{1}{N} \sum_{i = 1}^2 P(\omega_i) \varepsilon_i (1 - \varepsilon_i) \\
\end{gathered}$$

由期望$E[\hat{\varepsilon}'] = \varepsilon$可知，$\hat{\varepsilon}'$为$\varepsilon$的无偏估计量。

***
对于这两种估计值的差别，由于二者都是无偏估计量，我们考虑其统计特性，即方差的差别
$$\begin{aligned}
    \text{var}(\hat{\varepsilon}) - \text{var}(\hat{\varepsilon}') =& \dfrac{1}{N}(\varepsilon(1 - \varepsilon) - \sum_{i = 1}^2 P(\omega_i)\varepsilon_i(1 - \varepsilon_i)) \\
    =& \dfrac{1}{N} (P(\omega_1)P(\omega_2)(\varepsilon_1 - \varepsilon_2)^2) \geq 0
\end{aligned}$$

从而选择性抽样得到的错误率估计的方差$\text{var}(\hat{\varepsilon}')$一般小于随机抽样得到的错误率估计的方差。

以上二分类问题的结论可以推广到多分类问题，只需要将$\sum$和$\prod$的上限由$2$改成$c$（$c$为分类数）即可。
可知这些估计为：
1. 这些估计是在最大似然估计意义上最好的估计。
2. 它们是错误率$\varepsilon$的无偏估计量。
3. 从置信区间的讨论可见，随着样本数$N$的增加，其置信区间相应地缩小。

### 交叉验证
**$n$折交叉验证法：** 将全部样本随机划分为$n$个等份，一轮实验中轮流抽出其中$1$份作为测试样本，其余$n - 1$份作为训练样本，得到$n$个错误率后取平均，作为一轮交叉验证的错误率。常常会进行$k(k > 1)$轮交叉验证。
**留一交叉验证法：** 每轮只取一个样本作为测试样本，剩下的都是训练样本，重复$N$（$N$为样本数）次。

二者都是对错误率的最大似然估计，但样本数有限时，这种估计是有偏的，因为每次训练没有使用全部样本；留一法的偏差更小，但方差更大。

### 自举法与$0.632$估计
#### 自举法（bootstrap法）
考虑一个大小为$N$的样本集，随机地从中有放回地抽取$N$个样本组成一个新样本集，这个新样本就称作**自举样本集**。
自举的思想：从原始样本集中进行$B$次自举采样，从每个自举样本集得到一次估计，用$B$个估计的平均作为最后的估计结果。

**用自举法估计错误率：** 从原数据中抽取$B$个自举样本集，用每个自举样本集训练一个分类器，用它来预测在该自举样本集中没有被抽到的样本，统计预测错误率并取平均，得到自举法估计的错误率。

#### $0.632$估计
由于自举法采样是又放回的抽样，一般其中会有重复样本。通常，一个自举样本集会包含原样本集中$63.2\%$左右的样本，导致自举法估计的错误率偏保守。
考虑到训练错误率是对真实错误率偏乐观的估计，而自举错误率是偏保守的估计，可以将二者进行结合；如此处的$0.632$估计：
$$\text{B}.632 = 0.368 \times \text{AE} + 0.632 \times \text{BI}$$

其中，$\text{AE}$为全部样本上的训练错误率，$\text{BI}$为自举错误率。

## 有限样本下错误率的区间估计
### 问题的提出
之前的所有方法都是对错误率的点估计，没有考虑样本集本身的随机性对分类性能的影响。
进一步地，**考虑样本的随机性，如果仅基于交叉验证，不存在错误率估计量的无偏估计**。

### 用扰动重采样估计SVM错误率的置信区间
假设有一组训练样本$(\bm{x}_1, y_1), (\bm{x}_2, y_2), ..., (\bm{x}_n, y_n)$，其中$\bm{x}$为样本的特征向量，$y$为对应的特征标号。在这组样本上获得的分类器输出为$f(\bm{x}; \hat{\theta})$，其中$\hat{\theta}$为支持向量机训练得到的最优参数。

假设从与样本集相同的分布中独立抽取一个样本$(\bm{x}_0, y_0)$，在这个样本上分类器的输出为$f(\bm{x}_0; \hat{\theta})$。定义**期望绝对错误率**：
$$\varepsilon = E[\left|y_0 - f(\bm{x}_0; \hat{\theta})\right|]$$

我们通常只考虑对未见到的所有可能样本的错误率，即上式中只对测试样本$(\bm{x}_0, y_0)$求数学期望，这样得到的错误率是对在给定的训练样本上得到的固定分类器的评价。实际上，训练样本本身也是从总体分布中的一次随机抽样，在对方发进行研究和比较时，需要考查的是方法在所研究的问题上而不是该特定数据上的性能，从而上式中还应该对样本集求期望。

**训练错误率**，即**重代入错误率**，是对期望错误率的最简单估计
$$\varepsilon_{\text{re}} = \dfrac{1}{n} \sum_{i = 1}^n |y_i - f(\bm{x}_i; \hat{\theta})|$$

此处，当$n$不充分大时，估计会偏乐观，即错误率被低估。

对$K$折交叉验证法，每次除去第$k$个子集得到的样本训练分类器得到的参数为$\hat{\theta}_{(-k)}$，用所得分类器得到在第$k$个子集上的错误率$\varepsilon_{(k)}(\hat{\theta}_{(-k)})$，各轮实验错误率的平均就是**交叉验证错误率**
$$\varepsilon_{\text{CV}} = \dfrac{1}{K} \sum_{k = 1}^K \varepsilon_{(k)}(\hat{\theta}_{(-k)})$$

为了研究在考虑到训练与测试样本两方面随机性的情况下，训练错误率、交叉错误率和期望错误率的关系，考查统计量
$$W = n^{\frac{1}{2}}(\varepsilon_{\text{re}} - \varepsilon)$$

的分布情况。可以证明，$W$渐进收敛于一个均值为$0$的正态分布。
对$K$折交叉验证法，当$K$固定且相对于样本数较小，同样可以证明，统计量
$$W_{\text{CV}} = n^{\frac{1}{2}}(\varepsilon_{\text{CV}} - \varepsilon)$$

在渐进意义下等价于$W$，可以通过估计$W$的分布来近似$W_{\text{CV}}$的分布。
理论上，我们可以推导$W_{\text{CV}}$的方差，但是其估计需要计算未知非参数的梯度，尤其是当特定参数$\theta$的维数较高时，计算更加困难。为了克服这些困难，我们使用**扰动重采样法**来估计统计量$W_{\text{CV}}$的分布。

令$\{G_i,\ i = 1, 2, ..., n\}$为一组与观测数据相互独立且具有单位均值和方差的独立同分布正值随机数。实际应用中，可以用**指数分布**来产生这样一组随机数。对于给定的一组随机数$\{G_i,\ i = 1, 2, ..., n\}$，定义目标函数
$$\hat{Q}_n^*(\theta) = \dfrac{1}{n} \sum_{i = 1}^n G_i ((1 - y_i f(\bm{x}_i, \theta))_+ + \lambda_n \bm{w} \cdot \bm{w})$$

并令$\theta^*$为最小化$\hat{Q}_n^*(\theta)$的解。
再令
$$W^* = n^{\frac{1}{2}}\sum_{i = 1}^n G_i (|y_i - f(\bm{x}_i; \theta^*)|)$$

可以证明，在给定训练样本的条件下，$W^*$的分布可以很好近似$W_{\text{CV}}$的分布。

事实上，对比$\hat{Q}_n^*(\theta)$和支持向量机目标函数，可以看到其具有相同形式：第一项$(1 - y_i f(\bm{x}_i, \theta))_+$就是支持向量机中的松弛因子项，第二项$(\lambda_n \bm{w} \cdot \bm{w})$就是分类间隔项。$\hat{Q}_n^*(\theta)$和支持向量机目标函数的区别，就是对每个样本都引入了一个随机的扰动因子$G_i$。这就是扰动重采样法。

与标准支持向量机相同，求解该优化问题可将其转化为对偶问题：
$$\begin{aligned}
    \max \quad& \sum_{i = 1}^n \alpha_i - \dfrac{1}{2} \sum_{i, j = 1}^n \alpha_i y_i(\bm{x}_i \cdot \bm{x}_j)y_j \alpha_j \\
    s.t. \quad& \sum_{i = 1}^n \alpha_i y_i = 0\\
    & 0 \leq \alpha_i \leq CG_i, \quad i = 1, 2, ..., n
\end{aligned}$$

从而求得原问题的解
$$\bm{w}^* = \dfrac{\sum\limits_{i = 1}^n \alpha_i y_i \bm{x}_i}{n^{-1}\sum\limits_{i = 1}^n G_i}$$

此处与标准的支持向量机的唯一区别，在于条件$0 \leq \alpha_i \leq CG_i$中多了对应于每一个样本的随机数因子$G_i$。

对于一组随机扰动因子$\{G_i,\ i = 1, 2, ..., n\}$，求解上式的支持向量机，用得到的解就可以得到$W^*$的一次实现值。由于$W^*$的分布能够近似$W_{\text{CV}}$的分布，我们可以产生多组随机扰动因子来得到大量$W^*$的取值，即对$W^*$的分布大量采样，利用这些数据估计$W_{\text{CV}}$的分布，进而估计根据交叉验证错误率$\varepsilon_{CV}$给出对期望错误率$\varepsilon$的估计。
例如，$\varepsilon$的$100(1 - \alpha)\%$置信区间可以根据下式估计
$$[\varepsilon_{CV} - n^{-\frac{1}{2}} \hat{\xi}_{1 - \frac{\alpha}{2}}, \varepsilon_{CV} + n^{-\frac{1}{2}} \hat{\xi}_{1 - \frac{\alpha}{2}}]$$

其中$\hat{\xi}_{1 - \frac{\alpha}{2}}$为$W^*$的采样分布的$\alpha$百分点。

**基本过程：**
1. 用事先给出的数据集训练支持向量机，并计算交叉验证错误率$\varepsilon_{\text{CV}}$。
2. 事先设定重采样次数$R$，对每一次重采样：
   1. 用指数分布产生均值和方差均为$1$的独立正随机数$\{G_i,\ i = 1, 2, ..., n\}$。
   2. 解扰动后的支持向量机式，并计算$W^*$。记第$r$次重采样得到的$W^*$为$W_r^*$。
3. 根据步骤2中得到的$\{W_r^*,\ r = 1, 2, ..., R\}$估计$W^*$的采样分布。
4. 计算错误率$\varepsilon$的置信区间。

扰动重采样方法的理论证明虽是在样本数目趋于无穷大的情况下给出的，但在样本数有限的情况下仍具有良好性能。同时，目前关于此方法的结论都是针对线性核的SVM的，推广到其他核函数和更多类型的分类器仍有待研究。

## 特征提取与选择对分类器性能估计的影响
实际问题中，我们常常需要**连同特征提取和选择一起来评价分类器性能**，即**评价特征提取与选择和分类器组成的模式识别系统的性能**。
如果将特征提取与选择和分类器看成一个整体，则前述所有方法都可以用于评价系统性能；但实际应用中，人们有时候倾向于忽略特征选取与提取过程，而只对系统中的分类器部分进行评价。

一种常见做法是，将所有样本进行特征选择或提取，而后把所选择和提取的特征固定下来，再把样本分成训练集和测试集，或者采用交叉验证的方法来估计分类器性能。用这种方法进行交叉验证的做法称为**CV1**。
在一些应用中，这种做法可能会导致**对分类性能的估计偏乐观**。
当样本数目比较多，而样本的初始特征维数并不是太高时，CV1交叉验证一般不会暴露出明显问题。但当初始维数很高，而样本数目相对较小时，即使很多特征中并不包含对实际分类有贡献的信息，由于样本的随机性，从大量特征中总能选择或变换出在优先样本上能够将两类较好分开的一些特征；如果以这些特征对分类器进行交叉验证，势必会得到较高的分类正确率，但这并不能反映样本真实情况。
导致这种现象的原因，在于特征选择或提取过程中的 **“信息泄露”** ：CV1方法在特征选择与提取时利用了全部样本，即在测试分类器性能前已经利用了来自将来测试样本的信息，因此导致最终对分类性能的过乐观估计。

严格的做法为：在对样本进行任何处理前就将待测试样本拿走，只用训练样本进行特征提取和选择，然后进行分类器设计，再用预留的测试样本对分类器进行测试。如果采用交叉验证，则需要在未作任何特征选择与提取前把测试样本和训练样本分开，在每一轮里只用训练样本选择和提取特征，这种做法称为**CV2**。
采用CV2进行交叉验证，可以得到对包括特征选择与提取部分在内的模式识别系统性能的真实估计，但仍然无法得到一组唯一的、用于分类的特征（交叉验证的每一轮运行中所选出的特征都有可能不同）。
解决方法：
+ 利用所用样本重新进行一次特征选择和提取，得到唯一的特征组合，再在此基础上用所有样本设计分类器。
+ 或者，将CV2交叉验证中得到的各个特征方案进行综合，从中选择在各轮交叉验证中被选中次数最多的若干特征组成最后的特征集。

## 用分类性能进行关系判断
将一个问题描述成模式识别问题，基本前提是特征和分类之间存在依赖关系，即样本$\bm{x}$和类别$y$之间的系统$S$是存在的。
然而，在一些实际问题（尤其是从大量数据中寻找规律和知识的数据挖掘问题）中，有时候只能假设某些特征和某种分类间有联系；此时，应用模式识别方法的目的之一就是通过分类的效果来判断特征与分类间是否的确存在可以用于预测的关系。

这类问题和传统的模式识别问题有两个重要区别：
+ 初始特征维数特别高，但样本却非常少，通常只有数十到数百个。
+ $\bm{x}$和$y$之间的系统$S$往往是完全未知的，其存在性本身也无法确定。

我们需要考查：如果特征与分类间不存在函数依赖关系，即样本的类别标号与样本特征之间的关系是随机的，那么我们有多少机会得到这样的错误率（或正确率）？这个机会就是假设检验中的$P$值。

解决该问题的一种有效的方法是**随机置换法**：
在保持已知样本集中两类样本比例不变的情况下，随机打乱样本的类别标号。此时，用同样的特征选择、提取和分类方法进行分类，得到的分类性能就反映了这样的模式识别方法在无分类信息的数据上的表现。
多次重新随机置换样本类的标号，就可以统计出在没有分类信息情况下模式识别分类性能的空分布，然后把在真实数据上得到的性能估计与这个空分布进行比较，得到分类器性能的随机置换$P$值。
如果该$P$值很小（通常以小于$0.05$作为参考），则说明在原样本集上得到的分类性能具有统计显著性，初步推断系统$S$很可能真实存在。

## 非监督模式识别系统性能的评价
### 聚类质量的评价
某些准则能够判断结果的显著性（即类别结构是否存在），这种评价称为**内部评价**。

#### 紧致性（一致性）
最常见的指标为**类内方差**或**平方误差和**，即$C$均值算法所局部优化的目标。除此之外，其它类内一致性度量还有**类内两两样本之间的平均/最大距离**、**平均/最大的基于之心的相似度**或**基于图理论的紧致性度量**。如采用下面的指标
$$V(C) = \sqrt{\dfrac{1}{N} \sum_{C_k \in C} \sum_{i \in C_k} \delta(i, \mu_k)}$$

其中，$N$为样本数目，$C$为所有聚类的集合，$\mu_k$为聚类$C_k$的质心，$\delta(\cdot, \cdot)$为所采用的距离度量。这个指标越小，聚类效果越好，其取值范围为$[0, +\infty)$。

#### 连接性质
其衡量了聚类是否遵循了样本的局部密度分布及相邻的样本是否被划分到同一类。这类指标中，有代表性的是**连接度**，即样本中相邻的数据点被划分到同一个聚类中的程度。其表达式为
$$\text{Conn}(C) = \sum_{i = 1}^N \sum_{j = 1}^L x_{i, nn_{i(j)}}$$

其中，$N$为样本数目，$L$控制有多少个近邻样本参与连接度计算。$x_{i, nn_{i(j)}}$满足：如果第$i$个样本的第$j$近邻与其不在同一个聚类中，则$x_{i, nn_{i(j)}} = \dfrac{1}{j}$，否则$x_{i, nn_{i(j)}} = 0$。这个指标越小，聚类效果越好，其取值范围为$[0, +\infty)$。

#### 分离度
其衡量了聚类间分离程度，如**平均/最小类间距离**，还可以用**两类中心距离**、**最近样本间距离**等准则。这个指标越大，聚类效果越好。

#### Silhouette宽度
将前面的直观指标进行组合，得到同时能反映类内距离和类间距离的新指标：
$$S(i) = \dfrac{b_i - a_i}{\max\{b_i, a_i\}}$$

其中，$a_i$为样本$i$到同类所有样本的平均距离，$b_i$为样本$i$到其他聚类中最近一个聚类的所有样本的平均距离。这样定义的$S(i)$称为**Silouette值**，所有样本的Silouette值的平均称为**Silouette宽度**。Silouette宽度越大，聚类效果越好，其取值范围为$[-1, 1]$。

#### Dunn宽度
$$D(C) = \dfrac{\min\limits_{C_k \in C \atop C_l \in C} \text{dist}(C_k, C_l)}{\max\limits_{C_m \in C} \text{diam}(C_m)}$$

其中，$\text{diam}(C_m)$为聚类$C_m$中最大的类内距离，$\text{dist}(C_k, C_l)$是$C_k$和$C_l$两类中相邻最近的样本对之间的距离。$D(C)$越大，聚类效果越好，其取值范围为$[0, +\infty)$。

#### 综合方法
由于没有先验认识，非监督学习的目标是多样的，无论采用什么方法混合多个指标，都不可避免地导致某些方面信息的损失。
另外一种不同的策略是，同时评价各个指标，并在当且仅当某一个方法在某一个指标上超出另一个方法、同时在所有指标上都等同于或超出该方法时，才断定该方法在聚类性能上胜过另一方法。

#### 预测效力
对于非监督模式识别系统的另一个重要评价指标就是其稳定性（结果的可重复性）。一种典型思想就是**采用重复地随机重采样，或者对样本加入随机扰动等方法，获得多个不同的样本集，在不同的样本集上实施同样的聚类算法，并定义某个统计量来比较聚类结果的一致性。**

**预测效力**的具体做法是：
1. 将样本随机划分为两份，两份样本各自进行聚类。
2. 用其中一份得到的聚类结果作为临时训练样本，对另外一份中的样本实行最近邻法分类，比较这样的分类与直接在这份样本上的聚类划分之间的重合程度。重合程度越大，聚类结果越稳定。

实际应用中，常需要多次重复进行，取平均值作为稳定性度量。

### 聚类结果的比较
以下为部分用于比较两类聚类结果，或者将聚类结果与已知/预期的划分方案进行比较的指标。

#### 混淆矩阵
直接将两种类别划分方案列表，如方案1包含$m$个类别，方案2包含$n$个类别，则列出一张$m \times n$的表，第$i$行第$j$列表示同时属于方案1中第$i$类和方案2中第$j$类的样本个数。

#### F度量
设方案1的类别为$C_k,\ k = 1, 2, ..., K$，每类样本数为$N_k$；方案2的类别为$S_t,\ t = 1, 2, ..., T$，每类样本数为$N_t$，$C_k$和$S_t$共有的样本数为$N_{tk}$。
我们用$P(S_t, C_k) = \dfrac{N_{tk}}{N_k}$和$R(S_t, C_k) = \dfrac{N_{tk}}{N_t}$表示站在方案1和方案2角度，看有多大比例的样本与另外方案中的类重合。

根据F度量的定义，某一对$C_k$和$S_t$比较的F度量为
$$F(S_t, C_k) = \dfrac{2P(S_t, C_k) R(S_t, C_k)}{P(S_t, C_k) + R(S_t, C_k)}$$

如果认为$S_t$是期望的答案/用来比较的标准，则可以通过一个加权系数$b$来调整$F$度量：
$$F(S_t, C_k) = \dfrac{(b^2 + 1)P(S_t, C_k) R(S_t, C_k)}{b^2 P(S_t, C_k) + R(S_t, C_k)}$$

计算两套方案中所有两两类之间的$F$度量，寻找最大的对应类，并对标准中的各类进行求和，得到方案1和方案2相比的总的F度量：
$$F(C) = \sum_{t = 1}^T \dfrac{N_t}{N} \max_{k = 1, 2, ..., K} F(S_t, C_k)$$

其中$N$为总样本数。
F度量越大，两套方案越接近，其取值范围为$[0, 1]$。

#### Rand指数和ARI
**Rand指数**是基于对两套方案中具有相同类别关系的样本对所占比例定义的比较两套方案的方法。
设总共有$n$个样本，$a$为两套方案中都被分在同一类的样本对数目，$b$为两套方案中都被分开的样本对数目，$c$为方案1中分在同一类但方案2中分开的样本对数目，$d$为方案2中分在同一类但方案1中分开的样本对数目。则有Rand指数的定义：
$$R(U, V) = \dfrac{a + b}{a + b + c + d} = \dfrac{a + b}{C_n^2}$$

Rand指数越大，两套方案越接近，其取值范围为$[0, 1]$。

如果对样本集有两套随机划分，其Rand指数期望并非一个常数，尤其是当类别数较多时，大部分样本都会不在同一个类别中，导致Rand指数接近$1$。
一种改进就是**调整的Rand指数（ARI）**，其定义为
$$\dfrac{\text{实际指数} - \text{期望指数}}{\text{最大指数} - \text{期望指数}}$$

ARI指数越大，两套方案越接近，其取值范围为$[0, 1]$。
在随机划分是广义超几何分布的假设下，可以得到比较划分方案$U$和$V$的ARI指数为：
$$ARI(U, V) = \dfrac{\sum\limits_{lk}C_{n_{lk}}^2 - \dfrac{\sum\limits_l C_{n_{l.}}^2 \sum\limits_k C_{n_{.k}}^2}{C_n^2}}{\dfrac{1}{2}\left( \sum\limits_l C_{n_{l.}}^2 + \sum\limits_k C_{n_{.k}}^2 \right) - \dfrac{\sum\limits_l C_{n_{l.}}^2 \sum\limits_k C_{n_{.k}}^2}{C_n^2}}$$

其中，$n_{lk}$表示所有样本中被划分到$U$方案的$l$类和$V$方案的$k$类的样本数，$n_{l.}$表示所有样本中被划分到$U$方案的$l$类的样本数，$n_{.k}$表示所有样本中被划分到$V$方案的$k$类的样本数。

#### 共表矩阵与归一化闵可夫斯基距离
将在划分方案$U$中所有样本是否属于同一类表示为一个矩阵，同属一类则在交叉点取$1$，反之取$0$，则对每一套划分方案形成了一个矩阵$C_U$，称作**共表型矩阵**。
我们使用两套方案共表型矩阵之间的**归一化闵可夫斯基距离**来进行差异程度的度量：
$$M(U, V) = \dfrac{\parallel C_U - C_V \parallel}{\parallel C_U \parallel}$$

这一结果称为**闵可夫斯基打分**，分值越小，两套方案越接近，其取值范围为$[0, +\infty)$。
